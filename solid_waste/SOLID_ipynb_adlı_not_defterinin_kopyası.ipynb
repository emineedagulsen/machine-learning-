{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOLID.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OTTA2xyTF1R8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense,Conv2D, MaxPool2D,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r machine-learning-/  # first remove folder, if present\n",
        "!git clone https://github.com/emineedagulsen/machine-learning-"
      ],
      "metadata": {
        "id": "J5gKhHA0UHqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311c6eba-1a66-4049-a541-b2e9acea6d82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'machine-learning-/': No such file or directory\n",
            "Cloning into 'machine-learning-'...\n",
            "remote: Enumerating objects: 39443, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 39443 (delta 12), reused 22 (delta 5), pack-reused 39407\u001b[K\n",
            "Receiving objects: 100% (39443/39443), 823.96 MiB | 34.82 MiB/s, done.\n",
            "Resolving deltas: 100% (403/403), done.\n",
            "Checking out files: 100% (12279/12279), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetSize = 224 # pixel dimension after ImageDataGenerator has processed\n",
        "color = 'rgb' # use \"rgb\" for color images\n",
        "classMode='binary' # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "trainingFiles = 'machine-learning-/solid_waste/train' # change according to your setup\n",
        "testFile = 'machine-learning-/solid_waste/test'\n",
        "\n"
      ],
      "metadata": {
        "id": "Ho8VZYuxUHtb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingFiles2 = 'machine-learning-/solid_waste/train/black' # change according to your setup\n",
        "testFile2 = 'machine-learning-/solid_waste/test/black'\n",
        "trainingFiles3 = 'machine-learning-/solid_waste/train/white' # change according to your setup\n",
        "testFile3 = 'machine-learning-/solid_waste/test/white'"
      ],
      "metadata": {
        "id": "xlmAk2K-Uy94"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%pylab inline\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "#img = mpimg.imread(singleTestFile)\n",
        "#imgplot = plt.imshow(img)\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "Q3qFIHg7UHv4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,  # change pixel value from 0-255 to 0.0 - 1.0\n",
        "         shear_range=0.2, # distort the image sideways\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "        )\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "yjALrjvRUHyX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "-sDPI5CHPrD9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING FOR BLACK OR WHİTE\n"
      ],
      "metadata": {
        "id": "DpDdbrqGVFBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "        trainingFiles, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=11, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "621rlenxUH0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7ef1b4-d95f-4cdc-850b-883296d670a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 583 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(\n",
        "        testFile, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=7, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "n5LtJr_5UH3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2610e0-6176-4e71-83b8-f6adc9fda60e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 959 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TRAINING* FOR BLACK\n",
        "\n"
      ],
      "metadata": {
        "id": "HxvM6sd6VOFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set2 = train_datagen.flow_from_directory(\n",
        "        trainingFiles2, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=23, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "TTD9TffpVIGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8de5ee-f0b7-468f-98fa-0cac5524c064"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 322 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set2 = test_datagen.flow_from_directory(\n",
        "        testFile2, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=24, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "TgNpOFEDVXIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e095ed22-a015-4a3d-9fa1-c6ded16c120d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 698 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING FOR WHITE"
      ],
      "metadata": {
        "id": "vuTaW885Idm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set3 = train_datagen.flow_from_directory(\n",
        "        trainingFiles3, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=9, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "ZT-xyQXBIckk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8869c110-07e1-43ca-e463-171358cf5ad7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 261 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set3 = test_datagen.flow_from_directory(\n",
        "        testFile3, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=29, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "fXDqMfxXIdKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f538621-0bed-4c27-c77d-b1623b94fba7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 261 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL FOR BLACK-WHITE"
      ],
      "metadata": {
        "id": "JwqTaGcTVbRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential() # instantiate new model object\n",
        "\n",
        "model.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,3]))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "model.add(Flatten())\n",
        "# add fully connected layer (just as with DNN Step 11 above)\n",
        "model.add(Dense(15,activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam, loss ='binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "GHtOxNzhUPm6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=training_set, validation_data=test_set, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ljQeU-2MzQ7",
        "outputId": "387ba906-6aa0-4145-f8d4-e47265092749"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 [==============================] - 23s 424ms/step - loss: 0.3813 - accuracy: 0.8268 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 23s 428ms/step - loss: 0.0815 - accuracy: 0.9794 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 22s 422ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 22s 419ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.8742e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 22s 417ms/step - loss: 6.0896e-04 - accuracy: 1.0000 - val_loss: 2.6633e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 22s 419ms/step - loss: 3.8737e-04 - accuracy: 1.0000 - val_loss: 1.8941e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 22s 418ms/step - loss: 6.3202e-04 - accuracy: 1.0000 - val_loss: 2.1299e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 22s 419ms/step - loss: 3.3761e-04 - accuracy: 1.0000 - val_loss: 1.2618e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 22s 419ms/step - loss: 2.3219e-04 - accuracy: 1.0000 - val_loss: 1.1348e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 22s 419ms/step - loss: 9.0798e-04 - accuracy: 1.0000 - val_loss: 1.2751e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a2df4da10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "D8bVEoDCdFKh",
        "outputId": "f49c9ce1-3f6f-451e-f239-a7bf3ad1507e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137/137 [==============================] - 9s 63ms/step - loss: 1.2751e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0001275082177016884, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "XHN2SYUAUPsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e815f7-b486-4f78-bab4-b3c3cdda825d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'black': 0, 'white': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " MODEL FOR BLACK PLASTIC OR METAL"
      ],
      "metadata": {
        "id": "ayZDU2SuVhVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelA = Sequential() # instantiate new model object\n",
        "\n",
        "modelA.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,3])) # dimension of image, coming in from training set. \n",
        "               # here 28x28 pixel. '1' is number of color channels. B/W = 1, Color = 3.\n",
        "\n",
        "modelA.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "modelA.add(Flatten())\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(9,activation='relu'))\n",
        "\n",
        "\n",
        "modelA.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "modelA.compile(optimizer=adam, loss = 'binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "hTeqzZKvVg08"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.fit(x=training_set2, validation_data=test_set2, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1og3KpM-LxGX",
        "outputId": "94ae1446-24ff-4392-90bd-8b1903c1c749"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 14s 975ms/step - loss: 0.8805 - accuracy: 0.5963 - val_loss: 0.6734 - val_accuracy: 0.6963\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 13s 957ms/step - loss: 0.6002 - accuracy: 0.7205 - val_loss: 0.6791 - val_accuracy: 0.5258\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.5411 - accuracy: 0.7391 - val_loss: 0.7221 - val_accuracy: 0.5244\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 13s 965ms/step - loss: 0.5189 - accuracy: 0.7547 - val_loss: 0.6168 - val_accuracy: 0.6605\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 14s 961ms/step - loss: 0.5101 - accuracy: 0.7484 - val_loss: 0.6080 - val_accuracy: 0.6289\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.5197 - accuracy: 0.7422 - val_loss: 0.8452 - val_accuracy: 0.5258\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 0.5540 - accuracy: 0.7484 - val_loss: 0.5746 - val_accuracy: 0.6476\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.4644 - accuracy: 0.7702 - val_loss: 0.5174 - val_accuracy: 0.8209\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 13s 966ms/step - loss: 0.4613 - accuracy: 0.7640 - val_loss: 0.4954 - val_accuracy: 0.7292\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 13s 959ms/step - loss: 0.4371 - accuracy: 0.8012 - val_loss: 0.4558 - val_accuracy: 0.7708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a27253ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.evaluate(test_set2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iESZ3eWbJwI",
        "outputId": "7e2725bc-8de0-4493-f26a-ecd92c1e0ae4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 6s 190ms/step - loss: 0.4558 - accuracy: 0.7708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45579835772514343, 0.7707736492156982]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set2.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZfnqK03VyNQ",
        "outputId": "2c3f44cc-f5a9-4417-d074-643d5206b098"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glass': 0, 'metal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " MODEL FOR WHITE PLASTIC OR METAL\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGEs3JFfIn4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelB= Sequential() # instantiate new model object\n",
        "\n",
        "modelB.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,3])) # dimension of image, coming in from training set. \n",
        "               # here 28x28 pixel. '1' is number of color channels. B/W = 1, Color = 3.\n",
        "\n",
        "\n",
        "\n",
        "modelB.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "\n",
        "modelB.add(Flatten())\n",
        "\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "\n",
        "\n",
        "modelB.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "modelB.compile(optimizer=adam, loss = 'binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "kdb-2yHZImwX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.fit(x=training_set3, validation_data=test_set3, epochs=10)\n"
      ],
      "metadata": {
        "id": "l2y65cTvkCF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef61a5b4-9ad1-4451-92a4-b185de550d70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 9s 298ms/step - loss: 0.6745 - accuracy: 0.6245 - val_loss: 0.6433 - val_accuracy: 0.6475\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 8s 293ms/step - loss: 0.6316 - accuracy: 0.6552 - val_loss: 0.5938 - val_accuracy: 0.6590\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 8s 292ms/step - loss: 0.5923 - accuracy: 0.6743 - val_loss: 0.6460 - val_accuracy: 0.5172\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 8s 290ms/step - loss: 0.5854 - accuracy: 0.6897 - val_loss: 0.5679 - val_accuracy: 0.6782\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 8s 290ms/step - loss: 0.5468 - accuracy: 0.7088 - val_loss: 0.5182 - val_accuracy: 0.8621\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 8s 291ms/step - loss: 0.5359 - accuracy: 0.7241 - val_loss: 0.4877 - val_accuracy: 0.7816\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 8s 292ms/step - loss: 0.5294 - accuracy: 0.7548 - val_loss: 0.5053 - val_accuracy: 0.7126\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 8s 291ms/step - loss: 0.4913 - accuracy: 0.7854 - val_loss: 0.4510 - val_accuracy: 0.7969\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 8s 292ms/step - loss: 0.4898 - accuracy: 0.7893 - val_loss: 0.5105 - val_accuracy: 0.7241\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 9s 294ms/step - loss: 0.5144 - accuracy: 0.7318 - val_loss: 0.4372 - val_accuracy: 0.9157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a272775d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.evaluate(test_set3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX38sW6Nfv-H",
        "outputId": "cb37bf2f-1a29-4598-e19b-bc5cc64b9e21"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 2s 228ms/step - loss: 0.4372 - accuracy: 0.9157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4371514320373535, 0.9157088398933411]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set3.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVZRtek5InGN",
        "outputId": "37dc4c76-b92c-4ca7-cfff-0680ec87abef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glass': 0, 'metal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "singleTestFile ='machine-learning-/solid_waste/predict/black/glass/0 (129).jpg'#predict a single new image.\n",
        "\n",
        "test_image = image.load_img(singleTestFile, target_size=[targetSize,targetSize], color_mode=color)\n",
        "# here set the SAME parameters as on the training in Step 4.\n",
        "test_image = image.img_to_array(test_image) # convert image to array\n",
        "test_image = np.expand_dims(test_image,axis=0) # add one extra dimension to hold batch column.\n",
        "# axis=0 means that the new dimension will be added on the row. Axis = 1 will add to the column.\n",
        "result = model.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "result2 = modelA.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "result3 = modelB.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "\n",
        "\n",
        "print(\"result is: \" + str(result[0][0]))\n",
        "if result[0][0]>0.5:\n",
        "  print(\"WHITE\")  # depending on the value of training_set.class_indices\n",
        "  print(\"result for white background is: \" + str(result3[0][0]))\n",
        "  if result3[0][0]>0.5:\n",
        "      print(\"METAL\")  # depending on the value of training_set.class_indices\n",
        "\n",
        "  else:\n",
        "      print(\"GLASS\")\n",
        " \n",
        "\n",
        "else:\n",
        "  print(\"BLACK\")\n",
        "  print(\"result for black background is: \" + str(result2[0][0]))\n",
        "  if result2[0][0]>0.5:\n",
        "    print(\"METAL\")  # depending on the value of training_set.class_indices\n",
        "\n",
        "  else:\n",
        "    print(\"GLASS\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDZNN1X3vG3V",
        "outputId": "65c04a66-49d7-4638-e941-b04aa21278b9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is: 8.318052e-06\n",
            "BLACK\n",
            "result for black background is: 0.23272303\n",
            "GLASS\n"
          ]
        }
      ]
    }
  ]
}