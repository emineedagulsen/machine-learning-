{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOLID.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTTA2xyTF1R8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense,Conv2D, MaxPool2D,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r machine-learning-/  # first remove folder, if present\n",
        "!git clone https://github.com/emineedagulsen/machine-learning-"
      ],
      "metadata": {
        "id": "J5gKhHA0UHqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789441ad-4894-41b1-cdff-f74aa5284566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machine-learning-'...\n",
            "remote: Enumerating objects: 39438, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 39438 (delta 9), reused 24 (delta 5), pack-reused 39407\u001b[K\n",
            "Receiving objects: 100% (39438/39438), 823.95 MiB | 13.78 MiB/s, done.\n",
            "Resolving deltas: 100% (400/400), done.\n",
            "Checking out files: 100% (12279/12279), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetSize = 224 # pixel dimension after ImageDataGenerator has processed\n",
        "color = \"grayscale\" # use \"rgb\" for color images\n",
        "classMode='binary' # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "trainingFiles = 'machine-learning-/solid_waste/train' # change according to your setup\n",
        "testFile = 'machine-learning-/solid_waste/test'\n",
        "\n"
      ],
      "metadata": {
        "id": "Ho8VZYuxUHtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingFiles2 = 'machine-learning-/solid_waste/train/black' # change according to your setup\n",
        "testFile2 = 'machine-learning-/solid_waste/test/black'\n",
        "trainingFiles3 = 'machine-learning-/solid_waste/train/white' # change according to your setup\n",
        "testFile3 = 'machine-learning-/solid_waste/test/white'"
      ],
      "metadata": {
        "id": "xlmAk2K-Uy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%pylab inline\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "#img = mpimg.imread(singleTestFile)\n",
        "#imgplot = plt.imshow(img)\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "Q3qFIHg7UHv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,  # change pixel value from 0-255 to 0.0 - 1.0\n",
        "         shear_range=0.2, # distort the image sideways\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "        )\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "yjALrjvRUHyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "-sDPI5CHPrD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING FOR BLACK OR WHÄ°TE\n"
      ],
      "metadata": {
        "id": "DpDdbrqGVFBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "        trainingFiles, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=11, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "621rlenxUH0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba94b6f0-d6e4-4199-8aac-1d23e9b4020b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 583 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(\n",
        "        testFile, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=7, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "n5LtJr_5UH3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b36f00d-50a4-439c-d64e-eee3788755a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 959 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TRAINING* FOR BLACK\n",
        "\n"
      ],
      "metadata": {
        "id": "HxvM6sd6VOFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set2 = train_datagen.flow_from_directory(\n",
        "        trainingFiles2, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=23, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "TTD9TffpVIGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf26f20-50b9-4ddb-f2f0-b502862ed932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 322 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set2 = test_datagen.flow_from_directory(\n",
        "        testFile2, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=24, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "TgNpOFEDVXIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f541bf08-a028-4843-cc9c-663bc6f4c705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 698 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING FOR WHITE"
      ],
      "metadata": {
        "id": "vuTaW885Idm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set3 = train_datagen.flow_from_directory(\n",
        "        trainingFiles3, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=9, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "ZT-xyQXBIckk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1212b3d3-4f51-4c22-d148-fc3b9cd7857f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 261 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set3 = test_datagen.flow_from_directory(\n",
        "        testFile3, # path to folder with images\n",
        "        target_size=(targetSize, targetSize), # size of output image, here we used 28 x 28 pixel\n",
        "        batch_size=29, # how many images to load at a time\n",
        "        class_mode=classMode, # use 'categorical' for >2 class, 'binary' for two-class problems\n",
        "        color_mode=color)   # use 'grayscale' for black/white, 'rgb' for color"
      ],
      "metadata": {
        "id": "fXDqMfxXIdKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba3117c-6315-437a-b3bc-df9a69cda34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 261 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL FOR BLACK-WHITE"
      ],
      "metadata": {
        "id": "JwqTaGcTVbRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential() # instantiate new model object\n",
        "\n",
        "model.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,1]))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "model.add(Flatten())\n",
        "# add fully connected layer (just as with DNN Step 11 above)\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(14,activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam, loss ='binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "GHtOxNzhUPm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=training_set, validation_data=test_set, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ljQeU-2MzQ7",
        "outputId": "a3d5b7e6-0210-43c6-ddb4-f3998857f01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 [==============================] - 61s 1s/step - loss: 0.6790 - accuracy: 0.5506 - val_loss: 0.5430 - val_accuracy: 0.7278\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 17s 320ms/step - loss: 0.3791 - accuracy: 0.7581 - val_loss: 0.1650 - val_accuracy: 0.9885\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 17s 321ms/step - loss: 0.1928 - accuracy: 0.9914 - val_loss: 0.0564 - val_accuracy: 0.9969\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 17s 319ms/step - loss: 0.0628 - accuracy: 0.9983 - val_loss: 0.0163 - val_accuracy: 0.9990\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 17s 321ms/step - loss: 0.0266 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9990\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 17s 321ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 17s 325ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 17s 330ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 18s 343ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0025 - val_accuracy: 0.9990\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 17s 319ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1007bda550>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "D8bVEoDCdFKh",
        "outputId": "83364231-8d29-4687-97fb-72e5e99d4068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137/137 [==============================] - 12s 89ms/step - loss: 0.0239 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.023884302005171776, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "XHN2SYUAUPsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a068478-eae5-43c8-8872-85e37781ca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'black': 0, 'white': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " MODEL FOR BLACK PLASTIC OR METAL"
      ],
      "metadata": {
        "id": "ayZDU2SuVhVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelA = Sequential() # instantiate new model object\n",
        "\n",
        "modelA.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,1])) # dimension of image, coming in from training set. \n",
        "               # here 28x28 pixel. '1' is number of color channels. B/W = 1, Color = 3.\n",
        "\n",
        "modelA.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "modelA.add(Flatten())\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(9,activation='relu'))\n",
        "\n",
        "\n",
        "modelA.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "modelA.compile(optimizer=adam, loss = 'binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "hTeqzZKvVg08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.fit(x=training_set2, validation_data=test_set2, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1og3KpM-LxGX",
        "outputId": "304f02cb-781a-4baf-de66-671aad44dd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 11s 770ms/step - loss: 0.6477 - accuracy: 0.7050 - val_loss: 0.9667 - val_accuracy: 0.5244\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 10s 753ms/step - loss: 0.5903 - accuracy: 0.7391 - val_loss: 0.8664 - val_accuracy: 0.5244\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 10s 756ms/step - loss: 0.5751 - accuracy: 0.7391 - val_loss: 0.7792 - val_accuracy: 0.5244\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 10s 753ms/step - loss: 0.5445 - accuracy: 0.7391 - val_loss: 0.8413 - val_accuracy: 0.5244\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 10s 757ms/step - loss: 0.5024 - accuracy: 0.7453 - val_loss: 0.6153 - val_accuracy: 0.6461\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 10s 758ms/step - loss: 0.5213 - accuracy: 0.7484 - val_loss: 0.6325 - val_accuracy: 0.5802\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 0.4725 - accuracy: 0.7609 - val_loss: 0.6824 - val_accuracy: 0.5458\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 10s 753ms/step - loss: 0.4284 - accuracy: 0.8261 - val_loss: 0.8691 - val_accuracy: 0.5272\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 10s 760ms/step - loss: 0.4524 - accuracy: 0.7950 - val_loss: 0.8406 - val_accuracy: 0.5301\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 0.3686 - accuracy: 0.8540 - val_loss: 0.5410 - val_accuracy: 0.6648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f100fcf3910>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.evaluate(test_set2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iESZ3eWbJwI",
        "outputId": "e31f4235-14cb-4853-f724-4a0fd66d94da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 5s 179ms/step - loss: 0.5410 - accuracy: 0.6648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5409555435180664, 0.6647564172744751]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set2.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZfnqK03VyNQ",
        "outputId": "aba2262e-a0a8-4cc9-f9ac-0142460ba9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glass': 0, 'metal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " MODEL FOR WHITE PLASTIC OR METAL\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGEs3JFfIn4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelB= Sequential() # instantiate new model object\n",
        "\n",
        "modelB.add(Conv2D(filters=2,  # specify number of filters. Higher number for more complex images.\n",
        "               kernel_size=3,  # size of filter - typically 3, as in 3x3\n",
        "               activation=\"relu\", # activation function, often 'relu' on layers before last\n",
        "               input_shape=[targetSize,targetSize,1])) # dimension of image, coming in from training set. \n",
        "               # here 28x28 pixel. '1' is number of color channels. B/W = 1, Color = 3.\n",
        "\n",
        "\n",
        "\n",
        "modelB.add(MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "\n",
        "modelB.add(Flatten())\n",
        "\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "\n",
        "\n",
        "modelB.add(Dense(1, activation=\"sigmoid\")) # one single output neuron and sigmoid ac. func.\n",
        "\n",
        "adam = Adam(learning_rate=0.001)\n",
        "modelB.compile(optimizer=adam, loss = 'binary_crossentropy', metrics=['accuracy']) \n",
        "# here parameters are set to solve a two-class problem. Hence binary_crossentropy. "
      ],
      "metadata": {
        "id": "kdb-2yHZImwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.fit(x=training_set3, validation_data=test_set3, epochs=10)\n"
      ],
      "metadata": {
        "id": "l2y65cTvkCF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0b7654-2341-4691-9b01-159f9dc6f44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 7s 225ms/step - loss: 0.6615 - accuracy: 0.6284 - val_loss: 0.6267 - val_accuracy: 0.6475\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.6366 - accuracy: 0.6513 - val_loss: 0.5904 - val_accuracy: 0.6475\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 6s 216ms/step - loss: 0.6080 - accuracy: 0.6590 - val_loss: 0.5656 - val_accuracy: 0.6820\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 6s 218ms/step - loss: 0.5780 - accuracy: 0.6973 - val_loss: 0.5257 - val_accuracy: 0.6897\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 6s 216ms/step - loss: 0.5545 - accuracy: 0.7088 - val_loss: 0.5200 - val_accuracy: 0.6782\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.5342 - accuracy: 0.7471 - val_loss: 0.5088 - val_accuracy: 0.6935\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 6s 216ms/step - loss: 0.5207 - accuracy: 0.7280 - val_loss: 0.4676 - val_accuracy: 0.7356\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 6s 216ms/step - loss: 0.4894 - accuracy: 0.7778 - val_loss: 0.4658 - val_accuracy: 0.7203\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 6s 214ms/step - loss: 0.4985 - accuracy: 0.7739 - val_loss: 0.4687 - val_accuracy: 0.7203\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 6s 215ms/step - loss: 0.4643 - accuracy: 0.7969 - val_loss: 0.4280 - val_accuracy: 0.7778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f100810cf50>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.evaluate(test_set3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX38sW6Nfv-H",
        "outputId": "6de4b1eb-336e-4383-92dc-94207989cc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 2s 217ms/step - loss: 0.4280 - accuracy: 0.7778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4279775023460388, 0.7777777910232544]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set3.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVZRtek5InGN",
        "outputId": "76163125-b35c-4e2e-e47a-d375d780e35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glass': 0, 'metal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "singleTestFile ='machine-learning-/solid_waste/predict/black/glass/0 (129).jpg'#predict a single new image.\n",
        "\n",
        "test_image = image.load_img(singleTestFile, target_size=[targetSize,targetSize], color_mode=color)\n",
        "# here set the SAME parameters as on the training in Step 4.\n",
        "test_image = image.img_to_array(test_image) # convert image to array\n",
        "test_image = np.expand_dims(test_image,axis=0) # add one extra dimension to hold batch column.\n",
        "# axis=0 means that the new dimension will be added on the row. Axis = 1 will add to the column.\n",
        "result = model.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "result2 = modelA.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "result3 = modelB.predict(test_image/255.0) # remember to divide each pixel value by 255.0\n",
        "\n",
        "\n",
        "print(\"result is: \" + str(result[0][0]))\n",
        "if result[0][0]>0.5:\n",
        "  print(\"WHITE\")  # depending on the value of training_set.class_indices\n",
        "  print(\"result for white background is: \" + str(result3[0][0]))\n",
        "  if result3[0][0]>0.5:\n",
        "      print(\"METAL\")  # depending on the value of training_set.class_indices\n",
        "\n",
        "  else:\n",
        "      print(\"GLASS\")\n",
        " \n",
        "\n",
        "else:\n",
        "  print(\"BLACK\")\n",
        "  print(\"result for black background is: \" + str(result2[0][0]))\n",
        "  if result2[0][0]>0.5:\n",
        "    print(\"METAL\")  # depending on the value of training_set.class_indices\n",
        "\n",
        "  else:\n",
        "    print(\"GLASS\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDZNN1X3vG3V",
        "outputId": "64dd6baf-3bf6-44ec-a5af-c00a7139953d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is: 0.00015991926\n",
            "BLACK\n",
            "result for black background is: 0.20416096\n",
            "GLASS\n"
          ]
        }
      ]
    }
  ]
}